{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from NLPutils.models.dilatedconv import DilatedConv\n",
    "from NLPutils.models.dconv3 import DConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from NLPutils.trainers.dconv_trainer import DConvTrainer\n",
    "from NLPutils.trainers.dconv2 import DConvTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = '/data/ner/conll/eng.train'\n",
    "valid = '/data/ner/conll/eng.testa'\n",
    "test = '/data/ner/conll/eng.testb'\n",
    "word_embed_loc = '/data/embeddings/GoogleNews-vectors-negative300.bin'\n",
    "# word_embed_loc = '/data/embeddings/glove.6B/glove.6B.300d.txt'\n",
    "valsplit=0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14986\n",
      "Loaded  training data\n",
      "Using provided validation data\n",
      "Loaded test data\n"
     ]
    }
   ],
   "source": [
    "from NLPutils.util.conll_util import *\n",
    "from NLPutils.embeddings import Word2VecModel, RandomInitVecModel, GloVeModel\n",
    "\n",
    "maxs, maxw, vocab_ch, vocab_word = conllBuildVocab([train, valid,\n",
    "                                                    test])\n",
    "\n",
    "# Vocab LUTs\n",
    "word_vocab = None\n",
    "char_vocab = None\n",
    "\n",
    "word_vec = Word2VecModel(word_embed_loc, vocab_word, 0.25)\n",
    "# word_vec = GloVeModel(word_embed_loc, vocab_word, 0.25)\n",
    "word_vocab = word_vec.vocab\n",
    "\n",
    "# if FLAGS.charsz != FLAGS.wsz and FLAGS.cbow is True:\n",
    "#     print('Warning, you have opted for CBOW char embeddings, but have provided differing sizes for char embedding depth and word depth.  This is not possible, forcing char embedding depth to be word depth ' + FLAGS.wsz)\n",
    "#     FLAGS.charsz = FLAGS.wsz\n",
    "\n",
    "char_vec = RandomInitVecModel(16, vocab_ch, 0.25)\n",
    "char_vocab = char_vec.vocab\n",
    "\n",
    "f2i = {\"<PAD>\":0}\n",
    "\n",
    "ts, f2i, _ = conllSentsToIndices(train, word_vocab, char_vocab, maxs, maxw, f2i, 3)\n",
    "print(len(ts))\n",
    "print('Loaded  training data')\n",
    "\n",
    "if valid is not None:\n",
    "    print('Using provided validation data')\n",
    "    vs, f2i,_ = conllSentsToIndices(valid, word_vocab, char_vocab, maxs, maxw, f2i, 3)\n",
    "else:\n",
    "    ts, vs = validSplit(ts, valsplit)\n",
    "    print('Created validation split')\n",
    "\n",
    "\n",
    "es, f2i,txts = conllSentsToIndices(test, word_vocab, char_vocab, maxs, maxw, f2i, 3)\n",
    "print('Loaded test data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word embed weights shape:  (30291, 300)\n",
      "max sentence len 124\n",
      "f2i length 9\n"
     ]
    }
   ],
   "source": [
    "print('word embed weights shape: ', word_vec.weights.shape)\n",
    "print( 'max sentence len', maxs)\n",
    "print('f2i length', len(f2i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_feats Tensor(\"ner/ExpandDims:0\", shape=(?, 1, 124, 420), dtype=float32)\n",
      "filter_shape [1, 3, Dimension(420), 300]\n",
      "h0 Tensor(\"ner/relu:0\", shape=(?, 1, 124, 300), dtype=float32)\n",
      "last_output Tensor(\"ner/concat_1:0\", shape=(?, 1, 124, 300), dtype=float32)\n",
      "block output Tensor(\"ner/block/iterated-block/relu_2:0\", shape=(?, ?, ?, 300), dtype=float32)\n",
      "h_concat_squeeze Tensor(\"ner/block/Squeeze:0\", shape=(?, ?, 300), dtype=float32)\n",
      "h_concat_flat Tensor(\"ner/block/Reshape:0\", shape=(?, 300), dtype=float32)\n",
      "input_to_pred Tensor(\"ner/block/hidden_dropout/dropout/mul:0\", shape=(?, 300), dtype=float32)\n",
      "proj_width 300\n",
      "scores Tensor(\"ner/block/output/scores:0\", shape=(?, 9), dtype=float32)\n",
      "unflat_scores Tensor(\"ner/block/output/Reshape:0\", shape=(?, 124, 9), dtype=float32)\n",
      "block output Tensor(\"ner/block_1/iterated-block/relu_2:0\", shape=(?, ?, ?, 300), dtype=float32)\n",
      "h_concat_squeeze Tensor(\"ner/block_1/Squeeze:0\", shape=(?, ?, 300), dtype=float32)\n",
      "h_concat_flat Tensor(\"ner/block_1/Reshape:0\", shape=(?, 300), dtype=float32)\n",
      "input_to_pred Tensor(\"ner/block_1/hidden_dropout/dropout/mul:0\", shape=(?, 300), dtype=float32)\n",
      "proj_width 300\n",
      "scores Tensor(\"ner/block_1/output/scores:0\", shape=(?, 9), dtype=float32)\n",
      "unflat_scores Tensor(\"ner/block_1/output/Reshape:0\", shape=(?, 124, 9), dtype=float32)\n",
      "block output Tensor(\"ner/block_2/iterated-block/relu_2:0\", shape=(?, ?, ?, 300), dtype=float32)\n",
      "h_concat_squeeze Tensor(\"ner/block_2/Squeeze:0\", shape=(?, ?, 300), dtype=float32)\n",
      "h_concat_flat Tensor(\"ner/block_2/Reshape:0\", shape=(?, 300), dtype=float32)\n",
      "input_to_pred Tensor(\"ner/block_2/hidden_dropout/dropout/mul:0\", shape=(?, 300), dtype=float32)\n",
      "proj_width 300\n",
      "scores Tensor(\"ner/block_2/output/scores:0\", shape=(?, 9), dtype=float32)\n",
      "unflat_scores Tensor(\"ner/block_2/output/Reshape:0\", shape=(?, 124, 9), dtype=float32)\n",
      "crf=True, creating SLL\n",
      "crf=True, creating SLL\n",
      "crf=True, creating SLL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up word embedding visualization\n",
      "Writing metadata\n",
      "Training epoch 1.\n",
      "Train (Loss 0.0780) (185.126 sec)\n",
      "Validation (F1 = 0.8433) (Acc 50067/51409 = 0.9739) (9.690 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 2.\n",
      "\t(last improvement @ 1)\n",
      "Train (Loss 0.0275) (184.544 sec)\n",
      "Validation (F1 = 0.8854) (Acc 50366/51409 = 0.9797) (9.479 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 3.\n",
      "\t(last improvement @ 2)\n",
      "Train (Loss 0.0170) (184.135 sec)\n",
      "Validation (F1 = 0.8940) (Acc 50455/51409 = 0.9814) (9.470 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 4.\n",
      "\t(last improvement @ 3)\n",
      "Train (Loss 0.0119) (184.240 sec)\n",
      "Validation (F1 = 0.8693) (Acc 50256/51409 = 0.9776) (9.480 sec)\n",
      "Training epoch 5.\n",
      "\t(last improvement @ 3)\n",
      "Train (Loss 0.0081) (184.122 sec)\n",
      "Validation (F1 = 0.8978) (Acc 50488/51409 = 0.9821) (9.470 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 6.\n",
      "\t(last improvement @ 5)\n",
      "Train (Loss 0.0059) (184.112 sec)\n",
      "Validation (F1 = 0.9000) (Acc 50533/51409 = 0.9830) (9.492 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 7.\n",
      "\t(last improvement @ 6)\n",
      "Train (Loss 0.0051) (184.330 sec)\n",
      "Validation (F1 = 0.8969) (Acc 50537/51409 = 0.9830) (9.472 sec)\n",
      "Training epoch 8.\n",
      "\t(last improvement @ 6)\n",
      "Train (Loss 0.0046) (184.252 sec)\n",
      "Validation (F1 = 0.9058) (Acc 50581/51409 = 0.9839) (9.475 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 9.\n",
      "\t(last improvement @ 8)\n",
      "Train (Loss 0.0040) (184.411 sec)\n",
      "Validation (F1 = 0.9096) (Acc 50581/51409 = 0.9839) (9.477 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 10.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0038) (184.194 sec)\n",
      "Validation (F1 = 0.9026) (Acc 50548/51409 = 0.9833) (9.478 sec)\n",
      "Training epoch 11.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0032) (184.339 sec)\n",
      "Validation (F1 = 0.8985) (Acc 50504/51409 = 0.9824) (9.472 sec)\n",
      "Training epoch 12.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0035) (184.376 sec)\n",
      "Validation (F1 = 0.9031) (Acc 50584/51409 = 0.9840) (9.473 sec)\n",
      "Training epoch 13.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0029) (184.432 sec)\n",
      "Validation (F1 = 0.8989) (Acc 50514/51409 = 0.9826) (9.472 sec)\n",
      "Training epoch 14.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0032) (184.203 sec)\n",
      "Validation (F1 = 0.8965) (Acc 50472/51409 = 0.9818) (9.491 sec)\n",
      "Training epoch 15.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0780) (184.150 sec)\n",
      "Validation (F1 = 0.8992) (Acc 50479/51409 = 0.9819) (9.472 sec)\n",
      "Training epoch 16.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0025) (184.176 sec)\n",
      "Validation (F1 = 0.8931) (Acc 50515/51409 = 0.9826) (9.477 sec)\n",
      "Training epoch 17.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0027) (184.025 sec)\n",
      "Validation (F1 = 0.9027) (Acc 50527/51409 = 0.9828) (9.472 sec)\n",
      "Training epoch 18.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0029) (184.216 sec)\n",
      "Validation (F1 = 0.8594) (Acc 50123/51409 = 0.9750) (9.474 sec)\n",
      "Training epoch 19.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0028) (184.371 sec)\n",
      "Validation (F1 = 0.8901) (Acc 50416/51409 = 0.9807) (9.474 sec)\n",
      "Training epoch 20.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0033) (184.063 sec)\n",
      "Validation (F1 = 0.8962) (Acc 50505/51409 = 0.9824) (9.475 sec)\n",
      "Training epoch 21.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0024) (184.082 sec)\n",
      "Validation (F1 = 0.8653) (Acc 50216/51409 = 0.9768) (9.471 sec)\n",
      "Training epoch 22.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0022) (184.306 sec)\n",
      "Validation (F1 = 0.8859) (Acc 50439/51409 = 0.9811) (9.470 sec)\n",
      "Training epoch 23.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0030) (184.135 sec)\n",
      "Validation (F1 = 0.8923) (Acc 50440/51409 = 0.9812) (9.469 sec)\n",
      "Training epoch 24.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0023) (184.273 sec)\n",
      "Validation (F1 = 0.8917) (Acc 50466/51409 = 0.9817) (9.475 sec)\n",
      "Training epoch 25.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0025) (184.249 sec)\n",
      "Validation (F1 = 0.8919) (Acc 50464/51409 = 0.9816) (9.472 sec)\n",
      "Training epoch 26.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0024) (184.290 sec)\n",
      "Validation (F1 = 0.8948) (Acc 50416/51409 = 0.9807) (9.473 sec)\n",
      "Training epoch 27.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0025) (184.221 sec)\n",
      "Validation (F1 = 0.8929) (Acc 50415/51409 = 0.9807) (9.469 sec)\n",
      "Training epoch 28.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0019) (184.333 sec)\n",
      "Validation (F1 = 0.8845) (Acc 50396/51409 = 0.9803) (9.473 sec)\n",
      "Training epoch 29.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0022) (184.331 sec)\n",
      "Validation (F1 = 0.8818) (Acc 50313/51409 = 0.9787) (9.475 sec)\n",
      "Training epoch 30.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0026) (184.331 sec)\n",
      "Validation (F1 = 0.8872) (Acc 50421/51409 = 0.9808) (9.468 sec)\n",
      "Training epoch 31.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0019) (184.306 sec)\n",
      "Validation (F1 = 0.9050) (Acc 50547/51409 = 0.9832) (9.469 sec)\n",
      "Training epoch 32.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0031) (184.297 sec)\n",
      "Validation (F1 = 0.8868) (Acc 50423/51409 = 0.9808) (9.475 sec)\n",
      "Training epoch 33.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0022) (184.284 sec)\n",
      "Validation (F1 = 0.9008) (Acc 50517/51409 = 0.9826) (9.471 sec)\n",
      "Training epoch 34.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0025) (184.318 sec)\n",
      "Validation (F1 = 0.8946) (Acc 50480/51409 = 0.9819) (9.471 sec)\n",
      "Training epoch 35.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0037) (184.190 sec)\n",
      "Validation (F1 = 0.9012) (Acc 50536/51409 = 0.9830) (9.487 sec)\n",
      "Training epoch 36.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0014) (184.390 sec)\n",
      "Validation (F1 = 0.8946) (Acc 50469/51409 = 0.9817) (9.471 sec)\n",
      "Training epoch 37.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0052) (184.374 sec)\n",
      "Validation (F1 = 0.9002) (Acc 50518/51409 = 0.9827) (9.472 sec)\n",
      "Training epoch 38.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0016) (184.272 sec)\n",
      "Validation (F1 = 0.9032) (Acc 50506/51409 = 0.9824) (9.469 sec)\n",
      "Training epoch 39.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0025) (184.458 sec)\n",
      "Validation (F1 = 0.8953) (Acc 50509/51409 = 0.9825) (9.470 sec)\n",
      "Training epoch 40.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0023) (184.141 sec)\n",
      "Validation (F1 = 0.8820) (Acc 50382/51409 = 0.9800) (9.467 sec)\n",
      "Training epoch 41.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0023) (184.303 sec)\n",
      "Validation (F1 = 0.8954) (Acc 50442/51409 = 0.9812) (9.475 sec)\n",
      "Training epoch 42.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0028) (184.345 sec)\n",
      "Validation (F1 = 0.8928) (Acc 50437/51409 = 0.9811) (9.477 sec)\n",
      "Training epoch 43.\n",
      "\t(last improvement @ 9)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-41b3d28b4db4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m              \u001b[0mfscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m               \u001b[0mviz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m              crf=True)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#1 -- 86.55 dropout at .45 and 300 filters. stopped at epoc 24.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/NLPutils/trainers/dconv2.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, name, ts, f2i, vs, es, char_vec, word_vec, eval_out, batchsz, epochs, dropout, test_thresh, patience, rnn, maxlen, maxw, wsz, hsz, cfiltsz, optim, eta, crf, fscore, viz, clip, kernel_size, num_layers, num_iterations, word_keep, num_filt)\u001b[0m\n\u001b[1;32m    276\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t(last improvement @ %d)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlast_improved\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_keep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                             \u001b[0mthis_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/NLPutils/trainers/dconv2.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, ts, dropout, batchsz, model, sess, word_keep)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mex2dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_keep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "trainer = DConvTrainer(None, DConv, 'conll-ner-dconv-strubell-5')\n",
    "trainer.train('ner', ts, f2i, vs, es,\n",
    "             char_vec,\n",
    "             word_vec,\n",
    "             'eval',\n",
    "              batchsz=2**5,\n",
    "              optim='adam',\n",
    "              eta=0.0005,\n",
    "              epochs=500,\n",
    "              dropout=0.15,\n",
    "              patience=50,\n",
    "              cfiltsz='1,3,5,7',\n",
    "             maxlen=maxs,\n",
    "             maxw=maxw,\n",
    "              num_filt=300,\n",
    "             num_layers=3,\n",
    "             num_iterations=3,\n",
    "             fscore=1,\n",
    "              viz=1,\n",
    "             crf=True)\n",
    "\n",
    "#1 -- 86.55 dropout at .45 and 300 filters. stopped at epoc 24.\n",
    "#2 -- 86.7 dropout at .35, 350 filters.\n",
    "#3 -- added dilation 1 conv at end of block. 86.28\n",
    "#4 -- 3 layers, 3 iters. got much worse. peeked at 91.8 in training, started dropping.\n",
    "#5 -- layers in block should be 1,2,1 from strubell's code. lowered dropout to .15 -- layers would have been 1,1,1.\n",
    "#6 -- clipped gradients'\n",
    "#7 -- 3 layers, 2 iterations.\n",
    "\n",
    "#strubell-1 -- just trying it. only hits 85.5\n",
    "#strubell-2 -- glove embeddings -- holy shit. only hits 86 IN VALIDATION\n",
    "#strubell-3 -- glove embeddings hwy embeddings. hits almost 86.7 soo a little better?\n",
    "#strubell-4 -- trying word2vec again. 86.3\n",
    "#strubell-5 -- num_iter to 3"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
