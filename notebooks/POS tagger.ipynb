{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Confidence/NN)\n",
      "  (PP in/IN)\n",
      "  (NP the/DT pound/NN)\n",
      "  (VP is/VBZ widely/RB expected/VBN to/TO take/VB)\n",
      "  (NP another/DT sharp/JJ dive/NN)\n",
      "  if/IN\n",
      "  (NP trade/NN figures/NNS)\n",
      "  (PP for/IN)\n",
      "  (NP September/NNP)\n",
      "  ,/,\n",
      "  due/JJ\n",
      "  (PP for/IN)\n",
      "  (NP release/NN)\n",
      "  (NP tomorrow/NN)\n",
      "  ,/,\n",
      "  (VP fail/VB to/TO show/VB)\n",
      "  (NP a/DT substantial/JJ improvement/NN)\n",
      "  (PP from/IN)\n",
      "  (NP July/NNP and/CC August/NNP)\n",
      "  (NP 's/POS near-record/JJ deficits/NNS)\n",
      "  ./.)\n",
      "[(u'Confidence', u'NN', u'B-NP'), (u'in', u'IN', u'B-PP'), (u'the', u'DT', u'B-NP'), (u'pound', u'NN', u'I-NP'), (u'is', u'VBZ', u'B-VP'), (u'widely', u'RB', u'I-VP'), (u'expected', u'VBN', u'I-VP'), (u'to', u'TO', u'I-VP'), (u'take', u'VB', u'I-VP'), (u'another', u'DT', u'B-NP'), (u'sharp', u'JJ', u'I-NP'), (u'dive', u'NN', u'I-NP'), (u'if', u'IN', u'O'), (u'trade', u'NN', u'B-NP'), (u'figures', u'NNS', u'I-NP'), (u'for', u'IN', u'B-PP'), (u'September', u'NNP', u'B-NP'), (u',', u',', u'O'), (u'due', u'JJ', u'O'), (u'for', u'IN', u'B-PP'), (u'release', u'NN', u'B-NP'), (u'tomorrow', u'NN', u'B-NP'), (u',', u',', u'O'), (u'fail', u'VB', u'B-VP'), (u'to', u'TO', u'I-VP'), (u'show', u'VB', u'I-VP'), (u'a', u'DT', u'B-NP'), (u'substantial', u'JJ', u'I-NP'), (u'improvement', u'NN', u'I-NP'), (u'from', u'IN', u'B-PP'), (u'July', u'NNP', u'B-NP'), (u'and', u'CC', u'I-NP'), (u'August', u'NNP', u'I-NP'), (u\"'s\", u'POS', u'B-NP'), (u'near-record', u'JJ', u'I-NP'), (u'deficits', u'NNS', u'I-NP'), (u'.', u'.', u'O')]\n"
     ]
    }
   ],
   "source": [
    "print conll2000.chunked_sents('train.txt')[0]\n",
    "\n",
    "import nltk\n",
    "print nltk.chunk.tree2conlltags(conll2000.chunked_sents('train.txt')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conll_transform_sentence(sentence, i):\n",
    "    \"\"\"\n",
    "    i is the word position in the sentence.\n",
    "    \"\"\"\n",
    "    if i < 2:\n",
    "        no = \"<start>\"\n",
    "        nopos = \"<startPOS>\"\n",
    "        result = {'word_t1':no, 'pos_t1':nopos, 'word_t2':no, 'pos_t2':nopos, 'curr_word': sentence[i][0], 'curr_pos': sentence[i][1]}\n",
    "    else:\n",
    "        word_t1 = sentence[i-1][0]\n",
    "        pos_t1 = sentence[i-1][1]\n",
    "        word_t2 = sentence[i-2][0]\n",
    "        pos_t2 = sentence[i-2][1]\n",
    "        result = {'word_t1':word_t1, 'pos_t1':pos_t1, 'word_t2':word_t2, 'pos_t2':pos_t2, 'curr_word': sentence[i][0], 'curr_pos': sentence[i][1]}\n",
    "    return result\n",
    "\n",
    "def get_label(token):\n",
    "    return token[2]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "class SequentialTrainer(object):\n",
    "    \"\"\"sequentially train\"\"\"\n",
    "    def __init__(self, model, xform, label_func):\n",
    "        self._model = model\n",
    "        self._xform = xform\n",
    "        self._label_func = label_func\n",
    "        \n",
    "        self.enc = DictVectorizer()\n",
    "        self.lbls_enc = LabelEncoder()\n",
    "    \n",
    "    def train(self, training_sentences):\n",
    "        transformed_train_x = []\n",
    "        train_y = []\n",
    "        for sent in training_sentences:\n",
    "            for i in xrange(len(sent)):\n",
    "                label = self._label_func(sent[i])\n",
    "                temp = self._xform(sent, i)\n",
    "                transformed_train_x.append(temp)\n",
    "                train_y.append(label)\n",
    "\n",
    "        labels = self.lbls_enc.fit_transform(train_y)\n",
    "        encoded = self.enc.fit_transform(transformed_train_x)\n",
    "        \n",
    "        self._model.fit(encoded, labels)\n",
    "        self._model.enc = self.enc\n",
    "        self._model.lbls_enc = self.lbls_enc\n",
    "        self._model.xform = self._xform\n",
    "        \n",
    "        return self._model\n",
    "        \n",
    "    def eval(self, testing):\n",
    "        transformed_test_x = []\n",
    "        test_y = []\n",
    "        for sent in testing:\n",
    "            for i in xrange(len(sent)):\n",
    "                label = self._label_func(sent[i])\n",
    "                temp = self._xform(sent, i)\n",
    "                transformed_test_x.append(temp)\n",
    "                test_y.append(label)\n",
    "\n",
    "        labels = self.lbls_enc.transform(test_y)\n",
    "        encoded = self.enc.transform(transformed_test_x)\n",
    "        \n",
    "        predict = self._model.predict(encoded)\n",
    "        precision = precision_score(labels, predict)\n",
    "        recall = recall_score(labels, predict)\n",
    "        return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = (nltk.chunk.tree2conlltags(sent) for sent in conll2000.chunked_sents('train.txt'))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "st = SequentialTrainer(lr, conll_transform_sentence, get_label)\n",
    "st.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1082: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1172: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "testing = (nltk.chunk.tree2conlltags(sent) for sent in conll2000.chunked_sents('test.txt'))\n",
    "\n",
    "p,r = st.eval(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.930700475702\n",
      "0.930641450493\n"
     ]
    }
   ],
   "source": [
    "print p\n",
    "print r"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
