{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=9\n",
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1566878391460080251\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10978911847\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 2983136667303305452\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0f:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=9\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from NLPutils.models.dilatedconv import DilatedConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from NLPutils.trainers.dconv_trainer import DConvTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = '/data/datasets/ner/eng.train'\n",
    "valid = '/data/datasets/ner/eng.testa'\n",
    "test = '/data/datasets/ner/eng.testb'\n",
    "word_embed_loc = '/data/embeddings/GoogleNews-vectors-negative300.bin'\n",
    "valsplit=0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14986\n",
      "Loaded  training data\n",
      "Using provided validation data\n",
      "Loaded test data\n"
     ]
    }
   ],
   "source": [
    "from src.util.conll_util import *\n",
    "from src.embeddings import Word2VecModel, RandomInitVecModel\n",
    "\n",
    "maxs, maxw, vocab_ch, vocab_word = conllBuildVocab([train, valid,\n",
    "                                                    test])\n",
    "\n",
    "# Vocab LUTs\n",
    "word_vocab = None\n",
    "char_vocab = None\n",
    "\n",
    "word_vec = Word2VecModel(word_embed_loc, vocab_word, 0.25)\n",
    "word_vocab = word_vec.vocab\n",
    "\n",
    "# if FLAGS.charsz != FLAGS.wsz and FLAGS.cbow is True:\n",
    "#     print('Warning, you have opted for CBOW char embeddings, but have provided differing sizes for char embedding depth and word depth.  This is not possible, forcing char embedding depth to be word depth ' + FLAGS.wsz)\n",
    "#     FLAGS.charsz = FLAGS.wsz\n",
    "\n",
    "char_vec = RandomInitVecModel(16, vocab_ch, 0.25)\n",
    "char_vocab = char_vec.vocab\n",
    "\n",
    "f2i = {\"<PAD>\":0}\n",
    "\n",
    "ts, f2i, _ = conllSentsToIndices(train, word_vocab, char_vocab, maxs, maxw, f2i, 3)\n",
    "print(len(ts))\n",
    "print('Loaded  training data')\n",
    "\n",
    "if valid is not None:\n",
    "    print('Using provided validation data')\n",
    "    vs, f2i,_ = conllSentsToIndices(valid, word_vocab, char_vocab, maxs, maxw, f2i, 3)\n",
    "else:\n",
    "    ts, vs = validSplit(ts, valsplit)\n",
    "    print('Created validation split')\n",
    "\n",
    "\n",
    "es, f2i,txts = conllSentsToIndices(test, word_vocab, char_vocab, maxs, maxw, f2i, 3)\n",
    "print('Loaded test data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word embed weights shape:  (30291, 300)\n",
      "max sentence len 124\n"
     ]
    }
   ],
   "source": [
    "print('word embed weights shape: ', word_vec.weights.shape)\n",
    "print( 'max sentence len', maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/src/src/trainers/dconv3.py:55: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(length == len(guess[b]), \"lengths differ: length-- {}, len(guess[b])-- {} \".format(length, len(guess[b])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_feats Tensor(\"ner/ExpandDims:0\", shape=(?, 1, 124, 420), dtype=float32)\n",
      "filter_shape [1, 3, Dimension(420), 300]\n",
      "h0 Tensor(\"ner/relu:0\", shape=(?, 1, 124, 300), dtype=float32)\n",
      "last_output Tensor(\"ner/concat_1:0\", shape=(?, 1, 124, 300), dtype=float32)\n",
      "block output Tensor(\"ner/block/iterated-block/relu_2:0\", shape=(?, ?, ?, 300), dtype=float32)\n",
      "h_concat_squeeze Tensor(\"ner/block/Squeeze:0\", shape=(?, ?, 300), dtype=float32)\n",
      "h_concat_flat Tensor(\"ner/block/Reshape:0\", shape=(?, 300), dtype=float32)\n",
      "input_to_pred Tensor(\"ner/block/hidden_dropout/dropout/mul:0\", shape=(?, 300), dtype=float32)\n",
      "proj_width 300\n",
      "scores Tensor(\"ner/block/output/scores:0\", shape=(?, 9), dtype=float32)\n",
      "unflat_scores Tensor(\"ner/block/output/Reshape:0\", shape=(?, 124, 9), dtype=float32)\n",
      "block output Tensor(\"ner/block_1/iterated-block/relu_2:0\", shape=(?, ?, ?, 300), dtype=float32)\n",
      "h_concat_squeeze Tensor(\"ner/block_1/Squeeze:0\", shape=(?, ?, 300), dtype=float32)\n",
      "h_concat_flat Tensor(\"ner/block_1/Reshape:0\", shape=(?, 300), dtype=float32)\n",
      "input_to_pred Tensor(\"ner/block_1/hidden_dropout/dropout/mul:0\", shape=(?, 300), dtype=float32)\n",
      "proj_width 300\n",
      "scores Tensor(\"ner/block_1/output/scores:0\", shape=(?, 9), dtype=float32)\n",
      "unflat_scores Tensor(\"ner/block_1/output/Reshape:0\", shape=(?, 124, 9), dtype=float32)\n",
      "crf=True, creating SLL\n",
      "crf=True, creating SLL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up word embedding visualization\n",
      "Writing metadata\n",
      "Training epoch 1.\n",
      "Train (Loss 0.0516) (59.399 sec)\n",
      "Validation (F1 = 0.6535) (Acc 48461/51409 = 0.9427) (5.406 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 2.\n",
      "\t(last improvement @ 1)\n",
      "Train (Loss 0.0235) (52.549 sec)\n",
      "Validation (F1 = 0.7869) (Acc 49620/51409 = 0.9652) (4.392 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 3.\n",
      "\t(last improvement @ 2)\n",
      "Train (Loss 0.0168) (53.006 sec)\n",
      "Validation (F1 = 0.8327) (Acc 50050/51409 = 0.9736) (4.615 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 4.\n",
      "\t(last improvement @ 3)\n",
      "Train (Loss 0.0133) (53.232 sec)\n",
      "Validation (F1 = 0.8487) (Acc 50170/51409 = 0.9759) (4.631 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 5.\n",
      "\t(last improvement @ 4)\n",
      "Train (Loss 0.0113) (52.442 sec)\n",
      "Validation (F1 = 0.8607) (Acc 50282/51409 = 0.9781) (4.241 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 6.\n",
      "\t(last improvement @ 5)\n",
      "Train (Loss 0.0097) (52.307 sec)\n",
      "Validation (F1 = 0.8727) (Acc 50353/51409 = 0.9795) (4.469 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 7.\n",
      "\t(last improvement @ 6)\n",
      "Train (Loss 0.0087) (52.861 sec)\n",
      "Validation (F1 = 0.8508) (Acc 50254/51409 = 0.9775) (4.620 sec)\n",
      "Training epoch 8.\n",
      "\t(last improvement @ 6)\n",
      "Train (Loss 0.0081) (52.927 sec)\n",
      "Validation (F1 = 0.8926) (Acc 50513/51409 = 0.9826) (4.398 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 9.\n",
      "\t(last improvement @ 8)\n",
      "Train (Loss 0.0074) (52.891 sec)\n",
      "Validation (F1 = 0.8935) (Acc 50540/51409 = 0.9831) (4.503 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 10.\n",
      "\t(last improvement @ 9)\n",
      "Train (Loss 0.0070) (52.554 sec)\n",
      "Validation (F1 = 0.8943) (Acc 50546/51409 = 0.9832) (4.546 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 11.\n",
      "\t(last improvement @ 10)\n",
      "Train (Loss 0.0064) (53.293 sec)\n",
      "Validation (F1 = 0.8929) (Acc 50515/51409 = 0.9826) (4.586 sec)\n",
      "Training epoch 12.\n",
      "\t(last improvement @ 10)\n",
      "Train (Loss 0.0061) (52.054 sec)\n",
      "Validation (F1 = 0.8941) (Acc 50526/51409 = 0.9828) (4.720 sec)\n",
      "Training epoch 13.\n",
      "\t(last improvement @ 10)\n",
      "Train (Loss 0.0058) (53.626 sec)\n",
      "Validation (F1 = 0.8975) (Acc 50550/51409 = 0.9833) (4.475 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 14.\n",
      "\t(last improvement @ 13)\n",
      "Train (Loss 0.0053) (52.459 sec)\n",
      "Validation (F1 = 0.9025) (Acc 50611/51409 = 0.9845) (4.355 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 15.\n",
      "\t(last improvement @ 14)\n",
      "Train (Loss 0.0050) (52.585 sec)\n",
      "Validation (F1 = 0.9111) (Acc 50689/51409 = 0.9860) (4.244 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 16.\n",
      "\t(last improvement @ 15)\n",
      "Train (Loss 0.0047) (53.077 sec)\n",
      "Validation (F1 = 0.9067) (Acc 50607/51409 = 0.9844) (4.620 sec)\n",
      "Training epoch 17.\n",
      "\t(last improvement @ 15)\n",
      "Train (Loss 0.0046) (53.426 sec)\n",
      "Validation (F1 = 0.9106) (Acc 50672/51409 = 0.9857) (4.143 sec)\n",
      "Training epoch 18.\n",
      "\t(last improvement @ 15)\n",
      "Train (Loss 0.0043) (52.730 sec)\n",
      "Validation (F1 = 0.9059) (Acc 50626/51409 = 0.9848) (4.538 sec)\n",
      "Training epoch 19.\n",
      "\t(last improvement @ 15)\n",
      "Train (Loss 0.0041) (52.877 sec)\n",
      "Validation (F1 = 0.9101) (Acc 50648/51409 = 0.9852) (4.166 sec)\n",
      "Training epoch 20.\n",
      "\t(last improvement @ 15)\n",
      "Train (Loss 0.0041) (52.835 sec)\n",
      "Validation (F1 = 0.9130) (Acc 50696/51409 = 0.9861) (4.433 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 21.\n",
      "\t(last improvement @ 20)\n",
      "Train (Loss 0.0039) (52.926 sec)\n",
      "Validation (F1 = 0.9126) (Acc 50675/51409 = 0.9857) (3.888 sec)\n",
      "Training epoch 22.\n",
      "\t(last improvement @ 20)\n",
      "Train (Loss 0.0037) (53.513 sec)\n",
      "Validation (F1 = 0.9097) (Acc 50667/51409 = 0.9856) (4.212 sec)\n",
      "Training epoch 23.\n",
      "\t(last improvement @ 20)\n",
      "Train (Loss 0.0035) (52.287 sec)\n",
      "Validation (F1 = 0.9174) (Acc 50722/51409 = 0.9866) (4.287 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 24.\n",
      "\t(last improvement @ 23)\n",
      "Train (Loss 0.0033) (53.065 sec)\n",
      "Validation (F1 = 0.9101) (Acc 50647/51409 = 0.9852) (4.647 sec)\n",
      "Training epoch 25.\n",
      "\t(last improvement @ 23)\n",
      "Train (Loss 0.0032) (52.754 sec)\n",
      "Validation (F1 = 0.9194) (Acc 50747/51409 = 0.9871) (4.540 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 26.\n",
      "\t(last improvement @ 25)\n",
      "Train (Loss 0.0032) (52.733 sec)\n",
      "Validation (F1 = 0.9121) (Acc 50672/51409 = 0.9857) (4.643 sec)\n",
      "Training epoch 27.\n",
      "\t(last improvement @ 25)\n",
      "Train (Loss 0.0031) (52.529 sec)\n",
      "Validation (F1 = 0.9208) (Acc 50743/51409 = 0.9870) (4.521 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 28.\n",
      "\t(last improvement @ 27)\n",
      "Train (Loss 0.0029) (53.408 sec)\n",
      "Validation (F1 = 0.9202) (Acc 50738/51409 = 0.9869) (4.369 sec)\n",
      "Training epoch 29.\n",
      "\t(last improvement @ 27)\n",
      "Train (Loss 0.0029) (52.155 sec)\n",
      "Validation (F1 = 0.9187) (Acc 50731/51409 = 0.9868) (4.416 sec)\n",
      "Training epoch 30.\n",
      "\t(last improvement @ 27)\n",
      "Train (Loss 0.0027) (53.548 sec)\n",
      "Validation (F1 = 0.9202) (Acc 50747/51409 = 0.9871) (4.412 sec)\n",
      "Training epoch 31.\n",
      "\t(last improvement @ 27)\n",
      "Train (Loss 0.0026) (52.835 sec)\n",
      "Validation (F1 = 0.9186) (Acc 50727/51409 = 0.9867) (4.296 sec)\n",
      "Training epoch 32.\n",
      "\t(last improvement @ 27)\n",
      "Train (Loss 0.0025) (52.721 sec)\n",
      "Validation (F1 = 0.9184) (Acc 50690/51409 = 0.9860) (4.665 sec)\n",
      "Training epoch 33.\n",
      "\t(last improvement @ 27)\n",
      "Train (Loss 0.0024) (52.298 sec)\n",
      "Validation (F1 = 0.9222) (Acc 50764/51409 = 0.9875) (4.358 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 34.\n",
      "\t(last improvement @ 33)\n",
      "Train (Loss 0.0024) (53.209 sec)\n",
      "Validation (F1 = 0.9219) (Acc 50738/51409 = 0.9869) (4.759 sec)\n",
      "Training epoch 35.\n",
      "\t(last improvement @ 33)\n",
      "Train (Loss 0.0023) (51.965 sec)\n",
      "Validation (F1 = 0.9228) (Acc 50760/51409 = 0.9874) (4.762 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 36.\n",
      "\t(last improvement @ 35)\n",
      "Train (Loss 0.0022) (52.858 sec)\n",
      "Validation (F1 = 0.9232) (Acc 50760/51409 = 0.9874) (4.446 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 37.\n",
      "\t(last improvement @ 36)\n",
      "Train (Loss 0.0022) (52.314 sec)\n",
      "Validation (F1 = 0.9174) (Acc 50706/51409 = 0.9863) (4.642 sec)\n",
      "Training epoch 38.\n",
      "\t(last improvement @ 36)\n",
      "Train (Loss 0.0021) (52.747 sec)\n",
      "Validation (F1 = 0.9230) (Acc 50763/51409 = 0.9874) (4.377 sec)\n",
      "Training epoch 39.\n",
      "\t(last improvement @ 36)\n",
      "Train (Loss 0.0020) (52.265 sec)\n",
      "Validation (F1 = 0.9249) (Acc 50781/51409 = 0.9878) (4.574 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 40.\n",
      "\t(last improvement @ 39)\n",
      "Train (Loss 0.0021) (52.714 sec)\n",
      "Validation (F1 = 0.9200) (Acc 50732/51409 = 0.9868) (4.468 sec)\n",
      "Training epoch 41.\n",
      "\t(last improvement @ 39)\n",
      "Train (Loss 0.0019) (52.334 sec)\n",
      "Validation (F1 = 0.9226) (Acc 50748/51409 = 0.9871) (4.701 sec)\n",
      "Training epoch 42.\n",
      "\t(last improvement @ 39)\n",
      "Train (Loss 0.0019) (52.839 sec)\n",
      "Validation (F1 = 0.9175) (Acc 50698/51409 = 0.9862) (4.695 sec)\n",
      "Training epoch 43.\n",
      "\t(last improvement @ 39)\n",
      "Train (Loss 0.0020) (52.247 sec)\n",
      "Validation (F1 = 0.9213) (Acc 50731/51409 = 0.9868) (4.443 sec)\n",
      "Training epoch 44.\n",
      "\t(last improvement @ 39)\n",
      "Train (Loss 0.0019) (53.397 sec)\n",
      "Validation (F1 = 0.9255) (Acc 50779/51409 = 0.9877) (4.689 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 45.\n",
      "\t(last improvement @ 44)\n",
      "Train (Loss 0.0018) (52.643 sec)\n",
      "Validation (F1 = 0.9257) (Acc 50767/51409 = 0.9875) (4.623 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 46.\n",
      "\t(last improvement @ 45)\n",
      "Train (Loss 0.0017) (52.787 sec)\n",
      "Validation (F1 = 0.9167) (Acc 50709/51409 = 0.9864) (4.327 sec)\n",
      "Training epoch 47.\n",
      "\t(last improvement @ 45)\n",
      "Train (Loss 0.0018) (52.489 sec)\n",
      "Validation (F1 = 0.9252) (Acc 50765/51409 = 0.9875) (4.647 sec)\n",
      "Training epoch 48.\n",
      "\t(last improvement @ 45)\n",
      "Train (Loss 0.0017) (53.021 sec)\n",
      "Validation (F1 = 0.9264) (Acc 50776/51409 = 0.9877) (4.523 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 49.\n",
      "\t(last improvement @ 48)\n",
      "Train (Loss 0.0017) (52.464 sec)\n",
      "Validation (F1 = 0.9221) (Acc 50740/51409 = 0.9870) (4.473 sec)\n",
      "Training epoch 50.\n",
      "\t(last improvement @ 48)\n",
      "Train (Loss 0.0016) (53.472 sec)\n",
      "Validation (F1 = 0.9260) (Acc 50788/51409 = 0.9879) (4.891 sec)\n",
      "Training epoch 51.\n",
      "\t(last improvement @ 48)\n",
      "Train (Loss 0.0016) (52.155 sec)\n",
      "Validation (F1 = 0.9246) (Acc 50778/51409 = 0.9877) (4.398 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 52.\n",
      "\t(last improvement @ 48)\n",
      "Train (Loss 0.0016) (52.878 sec)\n",
      "Validation (F1 = 0.9253) (Acc 50769/51409 = 0.9876) (4.793 sec)\n",
      "Training epoch 53.\n",
      "\t(last improvement @ 48)\n",
      "Train (Loss 0.0015) (51.980 sec)\n",
      "Validation (F1 = 0.9274) (Acc 50794/51409 = 0.9880) (4.369 sec)\n",
      "Highest dev F1 achieved yet -- writing model\n",
      "Training epoch 54.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0015) (52.885 sec)\n",
      "Validation (F1 = 0.9269) (Acc 50793/51409 = 0.9880) (4.177 sec)\n",
      "Training epoch 55.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0015) (52.373 sec)\n",
      "Validation (F1 = 0.9231) (Acc 50765/51409 = 0.9875) (4.182 sec)\n",
      "Training epoch 56.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0015) (52.517 sec)\n",
      "Validation (F1 = 0.9223) (Acc 50763/51409 = 0.9874) (4.600 sec)\n",
      "Training epoch 57.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0014) (52.515 sec)\n",
      "Validation (F1 = 0.9221) (Acc 50748/51409 = 0.9871) (4.647 sec)\n",
      "Training epoch 58.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0014) (52.797 sec)\n",
      "Validation (F1 = 0.9185) (Acc 50726/51409 = 0.9867) (4.249 sec)\n",
      "Training epoch 59.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0015) (52.205 sec)\n",
      "Validation (F1 = 0.9254) (Acc 50780/51409 = 0.9878) (4.462 sec)\n",
      "Training epoch 60.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0015) (53.466 sec)\n",
      "Validation (F1 = 0.9239) (Acc 50782/51409 = 0.9878) (4.490 sec)\n",
      "Training epoch 61.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0013) (52.874 sec)\n",
      "Validation (F1 = 0.9263) (Acc 50783/51409 = 0.9878) (4.551 sec)\n",
      "Training epoch 62.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0014) (53.308 sec)\n",
      "Validation (F1 = 0.9262) (Acc 50788/51409 = 0.9879) (4.364 sec)\n",
      "Training epoch 63.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0014) (52.079 sec)\n",
      "Validation (F1 = 0.9248) (Acc 50766/51409 = 0.9875) (4.548 sec)\n",
      "Training epoch 64.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0013) (53.618 sec)\n",
      "Validation (F1 = 0.9243) (Acc 50772/51409 = 0.9876) (4.452 sec)\n",
      "Training epoch 65.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0013) (52.097 sec)\n",
      "Validation (F1 = 0.9219) (Acc 50753/51409 = 0.9872) (4.553 sec)\n",
      "Training epoch 66.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0013) (52.754 sec)\n",
      "Validation (F1 = 0.9238) (Acc 50768/51409 = 0.9875) (4.494 sec)\n",
      "Training epoch 67.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0013) (52.377 sec)\n",
      "Validation (F1 = 0.9213) (Acc 50730/51409 = 0.9868) (4.473 sec)\n",
      "Training epoch 68.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0014) (52.677 sec)\n",
      "Validation (F1 = 0.9175) (Acc 50713/51409 = 0.9865) (4.427 sec)\n",
      "Training epoch 69.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0013) (51.812 sec)\n",
      "Validation (F1 = 0.9255) (Acc 50768/51409 = 0.9875) (4.441 sec)\n",
      "Training epoch 70.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0012) (52.832 sec)\n",
      "Validation (F1 = 0.9261) (Acc 50773/51409 = 0.9876) (4.511 sec)\n",
      "Training epoch 71.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0013) (52.609 sec)\n",
      "Validation (F1 = 0.9256) (Acc 50765/51409 = 0.9875) (4.512 sec)\n",
      "Training epoch 72.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0012) (53.346 sec)\n",
      "Validation (F1 = 0.9260) (Acc 50777/51409 = 0.9877) (4.429 sec)\n",
      "Training epoch 73.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0012) (51.520 sec)\n",
      "Validation (F1 = 0.9230) (Acc 50761/51409 = 0.9874) (3.926 sec)\n",
      "Training epoch 74.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0012) (53.131 sec)\n",
      "Validation (F1 = 0.9267) (Acc 50780/51409 = 0.9878) (4.697 sec)\n",
      "Training epoch 75.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (52.427 sec)\n",
      "Validation (F1 = 0.9266) (Acc 50772/51409 = 0.9876) (4.439 sec)\n",
      "Training epoch 76.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (53.187 sec)\n",
      "Validation (F1 = 0.9257) (Acc 50775/51409 = 0.9877) (4.435 sec)\n",
      "Training epoch 77.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0012) (53.049 sec)\n",
      "Validation (F1 = 0.9225) (Acc 50743/51409 = 0.9870) (4.736 sec)\n",
      "Training epoch 78.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (52.905 sec)\n",
      "Validation (F1 = 0.9220) (Acc 50744/51409 = 0.9871) (4.623 sec)\n",
      "Training epoch 79.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0012) (52.674 sec)\n",
      "Validation (F1 = 0.9234) (Acc 50764/51409 = 0.9875) (4.668 sec)\n",
      "Training epoch 80.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (53.633 sec)\n",
      "Validation (F1 = 0.9245) (Acc 50771/51409 = 0.9876) (4.522 sec)\n",
      "Training epoch 81.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (52.721 sec)\n",
      "Validation (F1 = 0.9253) (Acc 50769/51409 = 0.9876) (4.623 sec)\n",
      "Training epoch 82.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (52.861 sec)\n",
      "Validation (F1 = 0.9241) (Acc 50768/51409 = 0.9875) (4.568 sec)\n",
      "Training epoch 83.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (51.996 sec)\n",
      "Validation (F1 = 0.9227) (Acc 50751/51409 = 0.9872) (4.512 sec)\n",
      "Training epoch 84.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (53.071 sec)\n",
      "Validation (F1 = 0.9217) (Acc 50756/51409 = 0.9873) (4.343 sec)\n",
      "Training epoch 85.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (52.451 sec)\n",
      "Validation (F1 = 0.9241) (Acc 50758/51409 = 0.9873) (4.477 sec)\n",
      "Training epoch 86.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (52.828 sec)\n",
      "Validation (F1 = 0.9269) (Acc 50783/51409 = 0.9878) (4.653 sec)\n",
      "Training epoch 87.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (52.457 sec)\n",
      "Validation (F1 = 0.9263) (Acc 50787/51409 = 0.9879) (4.289 sec)\n",
      "Training epoch 88.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (52.635 sec)\n",
      "Validation (F1 = 0.9262) (Acc 50786/51409 = 0.9879) (4.448 sec)\n",
      "Training epoch 89.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (52.448 sec)\n",
      "Validation (F1 = 0.9216) (Acc 50752/51409 = 0.9872) (4.649 sec)\n",
      "Training epoch 90.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (53.615 sec)\n",
      "Validation (F1 = 0.9266) (Acc 50784/51409 = 0.9878) (4.599 sec)\n",
      "Training epoch 91.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (52.899 sec)\n",
      "Validation (F1 = 0.9248) (Acc 50769/51409 = 0.9876) (4.490 sec)\n",
      "Training epoch 92.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0011) (52.944 sec)\n",
      "Validation (F1 = 0.9258) (Acc 50790/51409 = 0.9880) (4.615 sec)\n",
      "Training epoch 93.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (51.831 sec)\n",
      "Validation (F1 = 0.9225) (Acc 50759/51409 = 0.9874) (4.428 sec)\n",
      "Training epoch 94.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (53.955 sec)\n",
      "Validation (F1 = 0.9242) (Acc 50757/51409 = 0.9873) (4.440 sec)\n",
      "Training epoch 95.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (52.539 sec)\n",
      "Validation (F1 = 0.9249) (Acc 50779/51409 = 0.9877) (4.653 sec)\n",
      "Training epoch 96.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0009) (52.685 sec)\n",
      "Validation (F1 = 0.9254) (Acc 50776/51409 = 0.9877) (4.457 sec)\n",
      "Training epoch 97.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (52.249 sec)\n",
      "Validation (F1 = 0.9244) (Acc 50775/51409 = 0.9877) (4.344 sec)\n",
      "Training epoch 98.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (52.574 sec)\n",
      "Validation (F1 = 0.9261) (Acc 50776/51409 = 0.9877) (4.550 sec)\n",
      "Training epoch 99.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0009) (53.100 sec)\n",
      "Validation (F1 = 0.9264) (Acc 50786/51409 = 0.9879) (4.509 sec)\n",
      "Training epoch 100.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (53.162 sec)\n",
      "Validation (F1 = 0.9259) (Acc 50788/51409 = 0.9879) (4.359 sec)\n",
      "Training epoch 101.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0010) (52.630 sec)\n",
      "Validation (F1 = 0.9250) (Acc 50781/51409 = 0.9878) (4.395 sec)\n",
      "Training epoch 102.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0009) (53.944 sec)\n",
      "Validation (F1 = 0.9265) (Acc 50789/51409 = 0.9879) (4.455 sec)\n",
      "Training epoch 103.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0009) (52.384 sec)\n",
      "Validation (F1 = 0.9242) (Acc 50779/51409 = 0.9877) (4.415 sec)\n",
      "Training epoch 104.\n",
      "\t(last improvement @ 53)\n",
      "Train (Loss 0.0009) (53.176 sec)\n",
      "Validation (F1 = 0.9232) (Acc 50754/51409 = 0.9873) (4.523 sec)\n",
      "Stopping due to persistent failures to improve\n",
      "-----------------------------------------------------\n",
      "Highest dev F1 92.74\n",
      "=====================================================\n",
      "Evaluating best model on test data\n",
      "=====================================================\n",
      "Reloading conll-ner-dconv3-8/train/ner-6201\n",
      "Test (F1 = 0.8838) (Acc 45565/46665 = 0.9764) (300.268 sec)\n",
      "-----------------------------------------------------\n",
      "Test acc 97.64\n",
      "Test F1 88.38\n",
      "=====================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.models.dconv3.DConv at 0x7fd9ec2bdef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.models.dconv3 import DConv\n",
    "from src.trainers.dconv3 import DConvTrainer\n",
    "\n",
    "trainer = DConvTrainer(None, DConv, 'conll-ner-dconv3-8')\n",
    "trainer.train('ner', ts, f2i, vs, es,\n",
    "             char_vec,\n",
    "             word_vec,\n",
    "             'eval',\n",
    "              batchsz=2**7,\n",
    "              optim='adam',\n",
    "              eta=0.0005,\n",
    "              epochs=500,\n",
    "              dropout=0.15,\n",
    "              patience=50,\n",
    "              cfiltsz='1,3,5,7',\n",
    "             maxlen=maxs,\n",
    "             maxw=maxw,\n",
    "              num_filt=300,\n",
    "             num_layers=3,\n",
    "             num_iterations=2,\n",
    "             fscore=1,\n",
    "              viz=1,\n",
    "             crf=True)\n",
    "\n",
    "#1 -- 86.55 dropout at .45 and 300 filters. stopped at epoc 24.\n",
    "#2 -- 86.7 dropout at .35, 350 filters.\n",
    "#3 -- added dilation 1 conv at end of block. 86.28\n",
    "#4 -- 3 layers, 3 iters. got much worse. peeked at 91.8 in training, started dropping.\n",
    "#5 -- layers in block should be 1,2,1 from strubell's code. lowered dropout to .15 -- layers would have been 1,1,1.\n",
    "#6 -- clipped gradients'\n",
    "#7 -- 3 layers, 2 iterations.\n",
    "#8 -- 2**6 batch size, to reflect strubell's config. hit 91.9 in validation, 84.6 in test.\n",
    "#9 -- upped dropout to .35 from .15. 86.49\n",
    "#10 -- drop to .65.\n",
    "#11 -- removed a layer from the block. from 3 (block's dilation should be 1,2,1) to 2, (dilation to 1,1).\n",
    "#   -- 86.57\n",
    "#12 -- increasing iterations. blocks have 3 layers again.\n",
    "#13 -- lowered blocks to 2 layers. decreased eta to .00005. 86.82\n",
    "#14 -- lowered adam's epsilon from 1e-8 to 1e-6. eta to .0005 from .00005, batch size to 2**7 from 2**6. 86.46\n",
    "\n",
    "#strubell's dconv3\n",
    "#1 -- 83.6 F1. wtf is going on.\n",
    "#2 -- batch size up to 2**7. seems misconfigured with two dropouts..\n",
    "#3 -- she has middle dropout and hidden dropout in the same place. middle drop is not used, though. i missed this. 87.09\n",
    "#4  -- added word dropout straight to the word vectors. dropout == .85.  87.54\n",
    "#   -- I forgot to account for dropout keep in evaluation....\n",
    "#5 -- setting dropout keep to 1 in evaluation using pkeep and word_keep.  88.12\n",
    "#6 -- adding in gaussian noise to gradients according to https://arxiv.org/pdf/1511.06807.pdf --\n",
    "#  -- did flat normal noise, no scaling over t. 88.80. dropout at .65\n",
    "#7 -- increased noise variance to 0.01 from 0.001. 88.43\n",
    "#8 -- reverted noise variance to 0.001. changing dropout. my dropout is 1-dropout. it needs to be .15. 88.38"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
